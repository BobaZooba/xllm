{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "187Yhr0Hhs_r"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e75ddbd2ac1143f3b2b239724ebf19f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80fd0b86695e4886b57974183a892935",
       "IPY_MODEL_563f914a218d49f0b08407c876d2a31e",
       "IPY_MODEL_07eb9767f8ed422c9ad93542c25ac9dc"
      ],
      "layout": "IPY_MODEL_eadc2cd17cbc4c03a5db46169cc02571"
     }
    },
    "80fd0b86695e4886b57974183a892935": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cca3bdf63f342ec8554fb2928ed24fc",
      "placeholder": "​",
      "style": "IPY_MODEL_70e6228223b346f7ad58ffafdea144b2",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "563f914a218d49f0b08407c876d2a31e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7edad29e85614ad1beda830c8a31b245",
      "max": 685,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_daaa7540d5e74e0d990d86c6b3fdd7a1",
      "value": 685
     }
    },
    "07eb9767f8ed422c9ad93542c25ac9dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99c276f6f3c64729a072f6a8c0623f6a",
      "placeholder": "​",
      "style": "IPY_MODEL_83c7d74def0c420d8412901c01a2633a",
      "value": " 685/685 [00:00&lt;00:00, 15.8kB/s]"
     }
    },
    "eadc2cd17cbc4c03a5db46169cc02571": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cca3bdf63f342ec8554fb2928ed24fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70e6228223b346f7ad58ffafdea144b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7edad29e85614ad1beda830c8a31b245": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daaa7540d5e74e0d990d86c6b3fdd7a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99c276f6f3c64729a072f6a8c0623f6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83c7d74def0c420d8412901c01a2633a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2c6f9eedaa2423e9fb011605b9a00f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0daeeed03ecb4eaab883482885b6ab0d",
       "IPY_MODEL_650170fd50f040bc9055be8cda3925b6",
       "IPY_MODEL_a30d73fb7dfe4c709b216eca2a863834"
      ],
      "layout": "IPY_MODEL_577750148f99436381c29c590e81d18c"
     }
    },
    "0daeeed03ecb4eaab883482885b6ab0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_588d280713384af6b6d8b718c427f875",
      "placeholder": "​",
      "style": "IPY_MODEL_f1790af21831406db5e775f51492c272",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "650170fd50f040bc9055be8cda3925b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6ce2fdca8a14e8fa24a03dc84c10d84",
      "max": 644,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92c772d733ef4eecbe61a43e49ecda0f",
      "value": 644
     }
    },
    "a30d73fb7dfe4c709b216eca2a863834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb4611d5d7de49a0ae0ad4d786a0536d",
      "placeholder": "​",
      "style": "IPY_MODEL_138c825b677d4468b4de733d85938d42",
      "value": " 644/644 [00:00&lt;00:00, 17.4kB/s]"
     }
    },
    "577750148f99436381c29c590e81d18c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "588d280713384af6b6d8b718c427f875": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1790af21831406db5e775f51492c272": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6ce2fdca8a14e8fa24a03dc84c10d84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92c772d733ef4eecbe61a43e49ecda0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb4611d5d7de49a0ae0ad4d786a0536d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "138c825b677d4468b4de733d85938d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a9e8a595f464c23aeb6212eafa73401": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a497f050b9fe4b88aadc138e124949f3",
       "IPY_MODEL_fa61d7890bee464c8fc9a755ff5cfb57",
       "IPY_MODEL_f7ea6c801b3443898ac9e838e6cad646"
      ],
      "layout": "IPY_MODEL_a2b8172ea8834ded8300b3c80453abff"
     }
    },
    "a497f050b9fe4b88aadc138e124949f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6755e814c9243889a640703c9ef7b66",
      "placeholder": "​",
      "style": "IPY_MODEL_b6c2f7a0f3d142529b05ccf3168e36f7",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "fa61d7890bee464c8fc9a755ff5cfb57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49684b33f0394d40bda9d2d821b59e67",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47cbea844c3340d29b41be7d2659e175",
      "value": 898822
     }
    },
    "f7ea6c801b3443898ac9e838e6cad646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3fea2cc2b2f47ffbe07f3b503f59429",
      "placeholder": "​",
      "style": "IPY_MODEL_2daea45a521d4440b20996041547bcd2",
      "value": " 899k/899k [00:00&lt;00:00, 5.30MB/s]"
     }
    },
    "a2b8172ea8834ded8300b3c80453abff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6755e814c9243889a640703c9ef7b66": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6c2f7a0f3d142529b05ccf3168e36f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49684b33f0394d40bda9d2d821b59e67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47cbea844c3340d29b41be7d2659e175": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3fea2cc2b2f47ffbe07f3b503f59429": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2daea45a521d4440b20996041547bcd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "500d7f2f7d714ed9961361753a976ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55057d9005fc49a8bbb5cbf22106b07a",
       "IPY_MODEL_c1762cad76d54e60912638cfed044841",
       "IPY_MODEL_8f87c90fde834d99afd1cc437c0afd68"
      ],
      "layout": "IPY_MODEL_d3958b115023417db4daadc2d84490b5"
     }
    },
    "55057d9005fc49a8bbb5cbf22106b07a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6f2f582326b4bfaa188ec2f41d7468d",
      "placeholder": "​",
      "style": "IPY_MODEL_641517f1db9a466f885f135040185c07",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "c1762cad76d54e60912638cfed044841": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a236e93ded154cce9fc9e73251f8b920",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_512793907e824ffaa658eb7f0fc4c5c2",
      "value": 456318
     }
    },
    "8f87c90fde834d99afd1cc437c0afd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32ad64541599413e87d4a11b86942214",
      "placeholder": "​",
      "style": "IPY_MODEL_0fe22ae4f1e14129af98b1ae9d4ddf11",
      "value": " 456k/456k [00:00&lt;00:00, 7.68MB/s]"
     }
    },
    "d3958b115023417db4daadc2d84490b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6f2f582326b4bfaa188ec2f41d7468d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "641517f1db9a466f885f135040185c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a236e93ded154cce9fc9e73251f8b920": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "512793907e824ffaa658eb7f0fc4c5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32ad64541599413e87d4a11b86942214": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fe22ae4f1e14129af98b1ae9d4ddf11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da75dabfc8e84f549b2008417659dbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd98f69076984c048993d0c04692af21",
       "IPY_MODEL_47b7155a810e4378ad758fd82211637f",
       "IPY_MODEL_57fc0a0f1a5e4581910ba8c8ebff9907"
      ],
      "layout": "IPY_MODEL_8698e04b52474ff4b4ea917c1ad80828"
     }
    },
    "fd98f69076984c048993d0c04692af21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b96775a947149b7a66361d7898ee735",
      "placeholder": "​",
      "style": "IPY_MODEL_0fddee96c82149a9bac6607885dc56d5",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "47b7155a810e4378ad758fd82211637f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05df1ac99bdb474c972be9f65d835505",
      "max": 441,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49bf3d9d15964079bd63ab41c9762ef6",
      "value": 441
     }
    },
    "57fc0a0f1a5e4581910ba8c8ebff9907": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505b396dc31148bbb3e026615c1e61b3",
      "placeholder": "​",
      "style": "IPY_MODEL_c83e9278799846ee98beb374676f0067",
      "value": " 441/441 [00:00&lt;00:00, 23.3kB/s]"
     }
    },
    "8698e04b52474ff4b4ea917c1ad80828": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b96775a947149b7a66361d7898ee735": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fddee96c82149a9bac6607885dc56d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05df1ac99bdb474c972be9f65d835505": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49bf3d9d15964079bd63ab41c9762ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "505b396dc31148bbb3e026615c1e61b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c83e9278799846ee98beb374676f0067": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce9bd06caaf04de19afabfe2acddaa13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_32e51dbb2dfe49edb59fa2a0108b404a",
       "IPY_MODEL_4743852aa1a04dc6a71972f4e3cd7d2a",
       "IPY_MODEL_759d73748e324365ac1c6e559b75051e"
      ],
      "layout": "IPY_MODEL_b35d7badd49f4365bb4ed518123b4e2b"
     }
    },
    "32e51dbb2dfe49edb59fa2a0108b404a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89cfa4c7502c45619cc67247e54a3378",
      "placeholder": "​",
      "style": "IPY_MODEL_515d8a8063eb44828ad433d3d9c18f38",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "4743852aa1a04dc6a71972f4e3cd7d2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e63ea30a7d124eaa8981c11cd2c26798",
      "max": 662513657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a036e5b285e04b01870c91c2359e028f",
      "value": 662513657
     }
    },
    "759d73748e324365ac1c6e559b75051e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcee0c086eb04d7abba25d09660817e7",
      "placeholder": "​",
      "style": "IPY_MODEL_1e5bca925bf843c18dd23dcee73e3c71",
      "value": " 663M/663M [00:03&lt;00:00, 172MB/s]"
     }
    },
    "b35d7badd49f4365bb4ed518123b4e2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89cfa4c7502c45619cc67247e54a3378": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "515d8a8063eb44828ad433d3d9c18f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e63ea30a7d124eaa8981c11cd2c26798": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a036e5b285e04b01870c91c2359e028f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bcee0c086eb04d7abba25d09660817e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5bca925bf843c18dd23dcee73e3c71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34344651352149108d63b5c25c1c1d4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_752568203c3148ff8635a3724fad07cc",
       "IPY_MODEL_cd0bcf39ea134712acde1e0e6b956d0e",
       "IPY_MODEL_a565cc1c804249978355eed202aa33dc"
      ],
      "layout": "IPY_MODEL_b57cadfff8f347c98af165f51ea2756f"
     }
    },
    "752568203c3148ff8635a3724fad07cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20d8a436b74e4e1092d67332c9840ebe",
      "placeholder": "​",
      "style": "IPY_MODEL_d58f78cf02854cb4b846a6760953f82a",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "cd0bcf39ea134712acde1e0e6b956d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1cc7809540124b639b6cb75852cf4bea",
      "max": 137,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65beead907d34a189cdabc3d7cddeae1",
      "value": 137
     }
    },
    "a565cc1c804249978355eed202aa33dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_337f2303abc145e28de38ac08fa0c996",
      "placeholder": "​",
      "style": "IPY_MODEL_f3ea91342f384acf93dd7af65ea7c076",
      "value": " 137/137 [00:00&lt;00:00, 3.23kB/s]"
     }
    },
    "b57cadfff8f347c98af165f51ea2756f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20d8a436b74e4e1092d67332c9840ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d58f78cf02854cb4b846a6760953f82a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cc7809540124b639b6cb75852cf4bea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65beead907d34a189cdabc3d7cddeae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "337f2303abc145e28de38ac08fa0c996": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3ea91342f384acf93dd7af65ea7c076": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 🦖 X—LLM: Easy & Cutting Edge LLM Finetuning\n",
    "\n",
    "Tutorial how to run X—LLM in colab\n",
    "\n",
    "- [X—LLM Repo](https://github.com/BobaZooba/xllm): main repo of the `xllm` library\n",
    "- [Quickstart](https://github.com/KompleteAI/xllm/tree/docs-v1#quickstart-): basics of `xllm`\n",
    "- [Examples](https://github.com/BobaZooba/xllm/examples): minimal examples of using `xllm`\n",
    "- [Guide](https://github.com/BobaZooba/xllm/blob/main/GUIDE.md): here, we go into detail about everything the library can\n",
    "  do\n",
    "- [Demo project](https://github.com/BobaZooba/xllm-demo): here's a minimal step-by-step example of how to use X—LLM and fit it\n",
    "  into your own project\n",
    "- [WeatherGPT](https://github.com/BobaZooba/wgpt): this repository features an example of how to utilize the xllm library. Included is a solution for a common type of assessment given to LLM engineers, who typically earn between $120,000 to $140,000 annually\n",
    "- [Shurale](https://github.com/BobaZooba/shurale): project with the finetuned 7B Mistal model\n"
   ],
   "metadata": {
    "id": "nfE8HHxFECqI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First of all you need to install the latest `xllm` version"
   ],
   "metadata": {
    "id": "RK7mWDkLEqhX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installation"
   ],
   "metadata": {
    "id": "187Yhr0Hhs_r"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jluomCQ65wT",
    "outputId": "e2e8ad6a-648f-4c2c-c1e5-3ad3319419d0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting xllm\n",
      "  Downloading xllm-0.1.0-py3-none-any.whl (104 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from xllm) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from xllm) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from xllm) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from xllm) (2.1.0+cu118)\n",
      "Collecting loguru (from xllm)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft>=0.5.0 (from xllm)\n",
      "  Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb (from xllm)\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv (from xllm)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from xllm) (2.31.0)\n",
      "Collecting optimum>=1.12.0 (from xllm)\n",
      "  Downloading optimum-1.14.1-py3-none-any.whl (399 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bitsandbytes>=0.41.1 (from xllm)\n",
      "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xllm) (1.11.3)\n",
      "Collecting transformers (from xllm)\n",
      "  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from xllm) (4.66.1)\n",
      "Collecting safetensors (from xllm)\n",
      "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs (from optimum>=1.12.0->xllm)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum>=1.12.0->xllm) (1.12)\n",
      "Collecting huggingface-hub>=0.8.0 (from optimum>=1.12.0->xllm)\n",
      "  Downloading huggingface_hub-0.19.2-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets (from optimum>=1.12.0->xllm)\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft>=0.5.0->xllm) (6.0.1)\n",
      "Collecting accelerate>=0.21.0 (from peft>=0.5.0->xllm)\n",
      "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (4.5.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->xllm) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->xllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->xllm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->xllm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->xllm) (2023.7.22)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->xllm) (2023.6.3)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers->xllm)\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->xllm) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->xllm)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->xllm)\n",
      "  Downloading sentry_sdk-1.35.0-py2.py3-none-any.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->xllm)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle (from wandb->xllm)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->xllm) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->xllm) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->xllm) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->xllm) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->xllm)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.8.0 (from optimum>=1.12.0->xllm)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers->xllm)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum>=1.12.0->xllm)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum>=1.12.0->xllm) (9.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets->optimum>=1.12.0->xllm)\n",
      "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets->optimum>=1.12.0->xllm)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum>=1.12.0->xllm) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum>=1.12.0->xllm) (3.4.1)\n",
      "Collecting multiprocess (from datasets->optimum>=1.12.0->xllm)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum>=1.12.0->xllm) (3.8.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->xllm) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum>=1.12.0->xllm) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum>=1.12.0->xllm) (1.3.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->xllm)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum>=1.12.0->xllm) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum>=1.12.0->xllm) (2023.3.post1)\n",
      "Installing collected packages: sentencepiece, bitsandbytes, smmap, setproctitle, sentry-sdk, safetensors, python-dotenv, pyarrow-hotfix, loguru, humanfriendly, docker-pycreds, dill, multiprocess, huggingface-hub, gitdb, coloredlogs, tokenizers, GitPython, accelerate, wandb, transformers, datasets, peft, optimum, xllm\n",
      "Successfully installed GitPython-3.1.40 accelerate-0.24.1 bitsandbytes-0.41.2.post2 coloredlogs-15.0.1 datasets-2.14.7 dill-0.3.7 docker-pycreds-0.4.0 gitdb-4.0.11 huggingface-hub-0.17.3 humanfriendly-10.0 loguru-0.7.2 multiprocess-0.70.15 optimum-1.14.1 peft-0.6.2 pyarrow-hotfix-0.5 python-dotenv-1.0.0 safetensors-0.4.0 sentencepiece-0.1.99 sentry-sdk-1.35.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformers-4.35.1 wandb-0.16.0 xllm-0.1.0\n"
     ]
    }
   ],
   "source": [
    "# default version\n",
    "!pip install xllm\n",
    "\n",
    "# version which include deepspeed, flash-attn and auto-gptq\n",
    "# !pip install xllm[train]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verify the versions and confirm whether CUDA is available"
   ],
   "metadata": {
    "id": "dOmUEQGPFSPO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import xllm\n",
    "\n",
    "cuda_is_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"X—LLM version: {xllm.__version__}\\nTorch version: {torch.__version__}\\nCuda is available: {cuda_is_available}\")\n",
    "assert cuda_is_available"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpbY13qq7AIr",
    "outputId": "a3e2695e-05f3-4593-d68f-dc04f43aedcb"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X—LLM version: 0.1.0\n",
      "Torch version: 2.1.0+cu118\n",
      "Cuda is available: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single cell example"
   ],
   "metadata": {
    "id": "yX6IKojXS4JH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from xllm import Config\n",
    "from xllm.datasets import GeneralDataset\n",
    "from xllm.experiments import Experiment\n",
    "\n",
    "# 1. Init Config which controls the internal logic of xllm\n",
    "config = Config(\n",
    "    model_name_or_path=\"facebook/opt-350m\",\n",
    "    force_fp32=True,  # only for colab\n",
    ")\n",
    "\n",
    "# 2. Prepare the data\n",
    "train_data = [\"Hello!\"] * 100\n",
    "\n",
    "# 3. Load the data\n",
    "train_dataset = GeneralDataset.from_list(data=train_data)\n",
    "\n",
    "# 4. Init Experiment\n",
    "experiment = Experiment(config=config, train_dataset=train_dataset)\n",
    "\n",
    "# 5. Build Experiment from Config: init tokenizer and model, apply LoRA and so on\n",
    "experiment.build()\n",
    "\n",
    "# 6. Run Experiment (training)\n",
    "experiment.run()\n",
    "\n",
    "# 7. [Optional] Fuse LoRA layers\n",
    "# experiment.fuse_lora()\n",
    "\n",
    "# 8. [Optional] Push fused model (or just LoRA weight) to the HuggingFace Hub\n",
    "# experiment.push_to_hub(repo_id=\"YOUR_NAME/MODEL_NAME\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e75ddbd2ac1143f3b2b239724ebf19f2",
      "80fd0b86695e4886b57974183a892935",
      "563f914a218d49f0b08407c876d2a31e",
      "07eb9767f8ed422c9ad93542c25ac9dc",
      "eadc2cd17cbc4c03a5db46169cc02571",
      "8cca3bdf63f342ec8554fb2928ed24fc",
      "70e6228223b346f7ad58ffafdea144b2",
      "7edad29e85614ad1beda830c8a31b245",
      "daaa7540d5e74e0d990d86c6b3fdd7a1",
      "99c276f6f3c64729a072f6a8c0623f6a",
      "83c7d74def0c420d8412901c01a2633a",
      "f2c6f9eedaa2423e9fb011605b9a00f4",
      "0daeeed03ecb4eaab883482885b6ab0d",
      "650170fd50f040bc9055be8cda3925b6",
      "a30d73fb7dfe4c709b216eca2a863834",
      "577750148f99436381c29c590e81d18c",
      "588d280713384af6b6d8b718c427f875",
      "f1790af21831406db5e775f51492c272",
      "b6ce2fdca8a14e8fa24a03dc84c10d84",
      "92c772d733ef4eecbe61a43e49ecda0f",
      "fb4611d5d7de49a0ae0ad4d786a0536d",
      "138c825b677d4468b4de733d85938d42",
      "2a9e8a595f464c23aeb6212eafa73401",
      "a497f050b9fe4b88aadc138e124949f3",
      "fa61d7890bee464c8fc9a755ff5cfb57",
      "f7ea6c801b3443898ac9e838e6cad646",
      "a2b8172ea8834ded8300b3c80453abff",
      "d6755e814c9243889a640703c9ef7b66",
      "b6c2f7a0f3d142529b05ccf3168e36f7",
      "49684b33f0394d40bda9d2d821b59e67",
      "47cbea844c3340d29b41be7d2659e175",
      "b3fea2cc2b2f47ffbe07f3b503f59429",
      "2daea45a521d4440b20996041547bcd2",
      "500d7f2f7d714ed9961361753a976ac4",
      "55057d9005fc49a8bbb5cbf22106b07a",
      "c1762cad76d54e60912638cfed044841",
      "8f87c90fde834d99afd1cc437c0afd68",
      "d3958b115023417db4daadc2d84490b5",
      "c6f2f582326b4bfaa188ec2f41d7468d",
      "641517f1db9a466f885f135040185c07",
      "a236e93ded154cce9fc9e73251f8b920",
      "512793907e824ffaa658eb7f0fc4c5c2",
      "32ad64541599413e87d4a11b86942214",
      "0fe22ae4f1e14129af98b1ae9d4ddf11",
      "da75dabfc8e84f549b2008417659dbe6",
      "fd98f69076984c048993d0c04692af21",
      "47b7155a810e4378ad758fd82211637f",
      "57fc0a0f1a5e4581910ba8c8ebff9907",
      "8698e04b52474ff4b4ea917c1ad80828",
      "5b96775a947149b7a66361d7898ee735",
      "0fddee96c82149a9bac6607885dc56d5",
      "05df1ac99bdb474c972be9f65d835505",
      "49bf3d9d15964079bd63ab41c9762ef6",
      "505b396dc31148bbb3e026615c1e61b3",
      "c83e9278799846ee98beb374676f0067",
      "ce9bd06caaf04de19afabfe2acddaa13",
      "32e51dbb2dfe49edb59fa2a0108b404a",
      "4743852aa1a04dc6a71972f4e3cd7d2a",
      "759d73748e324365ac1c6e559b75051e",
      "b35d7badd49f4365bb4ed518123b4e2b",
      "89cfa4c7502c45619cc67247e54a3378",
      "515d8a8063eb44828ad433d3d9c18f38",
      "e63ea30a7d124eaa8981c11cd2c26798",
      "a036e5b285e04b01870c91c2359e028f",
      "bcee0c086eb04d7abba25d09660817e7",
      "1e5bca925bf843c18dd23dcee73e3c71",
      "34344651352149108d63b5c25c1c1d4a",
      "752568203c3148ff8635a3724fad07cc",
      "cd0bcf39ea134712acde1e0e6b956d0e",
      "a565cc1c804249978355eed202aa33dc",
      "b57cadfff8f347c98af165f51ea2756f",
      "20d8a436b74e4e1092d67332c9840ebe",
      "d58f78cf02854cb4b846a6760953f82a",
      "1cc7809540124b639b6cb75852cf4bea",
      "65beead907d34a189cdabc3d7cddeae1",
      "337f2303abc145e28de38ac08fa0c996",
      "f3ea91342f384acf93dd7af65ea7c076"
     ]
    },
    "id": "hS32uIgmdOor",
    "outputId": "fdf3fbe1-3739-44da-ca95-e9f9ebcb4822"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:07:34.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment building has started\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:34.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig:\n",
      "{\n",
      "  \"experiment_key\": \"base\",\n",
      "  \"save_safetensors\": true,\n",
      "  \"max_shard_size\": \"10GB\",\n",
      "  \"local_rank\": 0,\n",
      "  \"use_gradient_checkpointing\": false,\n",
      "  \"trainer_key\": \"lm\",\n",
      "  \"force_fp32\": true,\n",
      "  \"force_fp16\": false,\n",
      "  \"from_gptq\": false,\n",
      "  \"huggingface_hub_token\": null,\n",
      "  \"deepspeed_stage\": 0,\n",
      "  \"deepspeed_config_path\": null,\n",
      "  \"fsdp_strategy\": \"\",\n",
      "  \"fsdp_offload\": true,\n",
      "  \"seed\": 42,\n",
      "  \"stabilize\": false,\n",
      "  \"path_to_env_file\": \"./.env\",\n",
      "  \"prepare_dataset\": true,\n",
      "  \"lora_hub_model_id\": null,\n",
      "  \"lora_model_local_path\": null,\n",
      "  \"fused_model_local_path\": null,\n",
      "  \"fuse_after_training\": false,\n",
      "  \"quantization_dataset_id\": null,\n",
      "  \"quantization_max_samples\": 1024,\n",
      "  \"quantized_model_path\": \"./quantized_model/\",\n",
      "  \"quantized_hub_model_id\": null,\n",
      "  \"quantized_hub_private_repo\": true,\n",
      "  \"dataset_key\": \"soda\",\n",
      "  \"train_local_path_to_data\": \"./train.jsonl\",\n",
      "  \"eval_local_path_to_data\": null,\n",
      "  \"shuffle\": true,\n",
      "  \"max_eval_samples\": 1000,\n",
      "  \"add_eval_to_train_if_no_path\": false,\n",
      "  \"tokenizer_name_or_path\": null,\n",
      "  \"tokenizer_use_fast\": null,\n",
      "  \"tokenizer_padding_side\": null,\n",
      "  \"collator_key\": \"lm\",\n",
      "  \"max_length\": 2048,\n",
      "  \"model_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"push_to_hub_bos_add_bos_token\": false,\n",
      "  \"use_flash_attention_2\": false,\n",
      "  \"trust_remote_code\": false,\n",
      "  \"device_map\": null,\n",
      "  \"prepare_model_for_kbit_training\": null,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"load_in_4bit\": false,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_quantize_after_model_init\": false,\n",
      "  \"gptq_bits\": 4,\n",
      "  \"gptq_group_size\": 128,\n",
      "  \"gptq_disable_exllama\": true,\n",
      "  \"apply_lora\": false,\n",
      "  \"lora_rank\": 8,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"raw_lora_target_modules\": \"all\",\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"do_eval\": false,\n",
      "  \"per_device_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": null,\n",
      "  \"eval_delay\": 0,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"max_steps\": null,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"logging_steps\": 10,\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"push_to_hub\": false,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_private_repo\": true,\n",
      "  \"report_to_wandb\": false,\n",
      "  \"wandb_api_key\": null,\n",
      "  \"wandb_project\": null,\n",
      "  \"wandb_entity\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:34.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig saved\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:34.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecks passed successfully\u001b[0m\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "\u001b[32m2023-11-15 11:07:34.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining arguments was built:\n",
      "{\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"overwrite_output_dir\": false,\n",
      "  \"do_train\": false,\n",
      "  \"do_eval\": false,\n",
      "  \"do_predict\": false,\n",
      "  \"evaluation_strategy\": \"no\",\n",
      "  \"prediction_loss_only\": false,\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"per_device_eval_batch_size\": 2,\n",
      "  \"per_gpu_train_batch_size\": null,\n",
      "  \"per_gpu_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": 1,\n",
      "  \"eval_delay\": 0,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"adam_beta1\": 0.9,\n",
      "  \"adam_beta2\": 0.999,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"max_steps\": -1,\n",
      "  \"lr_scheduler_type\": \"linear\",\n",
      "  \"warmup_ratio\": 0.0,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"log_level\": \"info\",\n",
      "  \"log_level_replica\": \"warning\",\n",
      "  \"log_on_each_node\": true,\n",
      "  \"logging_dir\": \"./outputs/runs/Nov15_11-07-34_f0fdbaff8b8c\",\n",
      "  \"logging_strategy\": \"steps\",\n",
      "  \"logging_first_step\": true,\n",
      "  \"logging_steps\": 10,\n",
      "  \"logging_nan_inf_filter\": true,\n",
      "  \"save_strategy\": \"steps\",\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_on_each_node\": false,\n",
      "  \"no_cuda\": false,\n",
      "  \"use_cpu\": false,\n",
      "  \"use_mps_device\": false,\n",
      "  \"seed\": 42,\n",
      "  \"data_seed\": 42,\n",
      "  \"jit_mode_eval\": false,\n",
      "  \"use_ipex\": false,\n",
      "  \"bf16\": false,\n",
      "  \"fp16\": true,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"half_precision_backend\": \"auto\",\n",
      "  \"bf16_full_eval\": false,\n",
      "  \"fp16_full_eval\": false,\n",
      "  \"tf32\": null,\n",
      "  \"local_rank\": 0,\n",
      "  \"ddp_backend\": null,\n",
      "  \"tpu_num_cores\": null,\n",
      "  \"tpu_metrics_debug\": false,\n",
      "  \"debug\": [],\n",
      "  \"dataloader_drop_last\": false,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"dataloader_num_workers\": 0,\n",
      "  \"past_index\": -1,\n",
      "  \"run_name\": \"./outputs/\",\n",
      "  \"disable_tqdm\": false,\n",
      "  \"remove_unused_columns\": false,\n",
      "  \"label_names\": null,\n",
      "  \"load_best_model_at_end\": false,\n",
      "  \"metric_for_best_model\": \"loss\",\n",
      "  \"greater_is_better\": false,\n",
      "  \"ignore_data_skip\": false,\n",
      "  \"fsdp\": [],\n",
      "  \"fsdp_min_num_params\": 0,\n",
      "  \"fsdp_config\": {\n",
      "    \"min_num_params\": 0,\n",
      "    \"xla\": false,\n",
      "    \"xla_fsdp_grad_ckpt\": false\n",
      "  },\n",
      "  \"fsdp_transformer_layer_cls_to_wrap\": null,\n",
      "  \"deepspeed\": null,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"optim_args\": null,\n",
      "  \"adafactor\": false,\n",
      "  \"group_by_length\": false,\n",
      "  \"length_column_name\": \"length\",\n",
      "  \"report_to\": [\n",
      "    \"tensorboard\"\n",
      "  ],\n",
      "  \"ddp_find_unused_parameters\": null,\n",
      "  \"ddp_bucket_cap_mb\": null,\n",
      "  \"ddp_broadcast_buffers\": null,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"skip_memory_metrics\": true,\n",
      "  \"use_legacy_prediction_loop\": false,\n",
      "  \"push_to_hub\": false,\n",
      "  \"resume_from_checkpoint\": null,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_strategy\": \"checkpoint\",\n",
      "  \"hub_token\": \"<HUB_TOKEN>\",\n",
      "  \"hub_private_repo\": true,\n",
      "  \"hub_always_push\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"gradient_checkpointing_kwargs\": null,\n",
      "  \"include_inputs_for_metrics\": false,\n",
      "  \"fp16_backend\": \"auto\",\n",
      "  \"push_to_hub_model_id\": null,\n",
      "  \"push_to_hub_organization\": null,\n",
      "  \"push_to_hub_token\": \"<PUSH_TO_HUB_TOKEN>\",\n",
      "  \"mp_parameters\": \"\",\n",
      "  \"auto_find_batch_size\": false,\n",
      "  \"full_determinism\": false,\n",
      "  \"torchdynamo\": null,\n",
      "  \"ray_scope\": \"last\",\n",
      "  \"ddp_timeout\": 1800,\n",
      "  \"torch_compile\": false,\n",
      "  \"torch_compile_backend\": null,\n",
      "  \"torch_compile_mode\": null,\n",
      "  \"dispatch_batches\": null,\n",
      "  \"split_batches\": false,\n",
      "  \"include_tokens_per_second\": false,\n",
      "  \"neftune_noise_alpha\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:34.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEval dataset is None\u001b[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e75ddbd2ac1143f3b2b239724ebf19f2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2c6f9eedaa2423e9fb011605b9a00f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a9e8a595f464c23aeb6212eafa73401"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "500d7f2f7d714ed9961361753a976ac4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da75dabfc8e84f549b2008417659dbe6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:07:35.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTokenizer facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:35.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mCollator LMCollator was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:35.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuantization config is None. Model will be loaded using torch.float32\u001b[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce9bd06caaf04de19afabfe2acddaa13"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34344651352149108d63b5c25c1c1d4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:07:48.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel facebook/opt-350m was built\u001b[0m\n",
      "Using auto half precision backend\n",
      "\u001b[32m2023-11-15 11:07:59.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTrainer LMTrainer was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:59.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment built successfully\u001b[0m\n",
      "\u001b[32m2023-11-15 11:07:59.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining will start soon\u001b[0m\n",
      "***** Running training *****\n",
      "  Num examples = 100\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n",
      "  Number of trainable parameters = 331,196,416\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m2023-11-15 11:08:12.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining end\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel saved to ./outputs/\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add LoRA"
   ],
   "metadata": {
    "id": "Cr2WobXNrInd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Config\n",
    "\n",
    "`Config` plays a crucial role in the `xllm` library. It's how we define the workings of the library components, like how to handle data, the methods for training, the type of model to train, and so forth."
   ],
   "metadata": {
    "id": "PJHflQLiFznP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# config with LoRA\n",
    "config = Config(\n",
    "    model_name_or_path=\"facebook/opt-350m\",\n",
    "    apply_lora=True,\n",
    ")"
   ],
   "metadata": {
    "id": "5wRPWEC_7ACr"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### You can explicitly specify the values of additional parameters in LoRA"
   ],
   "metadata": {
    "id": "qrovyDw2uMzs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # extended config with LoRA\n",
    "# config = Config(\n",
    "#     model_name_or_path=\"facebook/opt-350m\",\n",
    "#     apply_lora=True,\n",
    "#     lora_rank=8,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.05,\n",
    "#     raw_lora_target_modules=\"all\",\n",
    "# )"
   ],
   "metadata": {
    "id": "PDZSBDkPuLTz"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make training data"
   ],
   "metadata": {
    "id": "vlu2UHTbuLAM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = [\"Hello!\", \"How are you?\", \"Are you okay?\"] * 100"
   ],
   "metadata": {
    "id": "1oUYinonrZP-"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dE8GhcaFHNq4",
    "outputId": "5f205d06-a871-4b7c-ac61-4b47b60832c0"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make a `xllm` train dataset"
   ],
   "metadata": {
    "id": "LHE8Wxh2IKbV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = GeneralDataset.from_list(data=train_data)"
   ],
   "metadata": {
    "id": "goJVNKvW6_81"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init the experiment\n",
    "\n",
    "`Experiment` encompasses all aspects of training, such as how to load the model, whether to use LoRA or not, and how to set up the trainer, among other things.\n",
    "\n",
    "Required field is `config`.\n",
    "\n",
    "You can also pass the arguments that are listed below. Default value for each component is `None`.\n",
    "\n",
    "If you do not explicitly specify the value when initializing the experiment (that is, by default it will be `None`), then `Experiment` in step `.build` initializes the necessary components by referring to `Config` such as `tokenizer`, `model`, and so on.\n",
    "```\n",
    "training_arguments: Optional[TrainingArguments]\n",
    "train_dataset: Optional[BaseDataset]\n",
    "eval_dataset: Optional[BaseDataset]\n",
    "tokenizer: Optional[PreTrainedTokenizer]\n",
    "collator: Optional[BaseCollator]\n",
    "quantization_config: Union[BitsAndBytesConfig, GPTQConfig, None]\n",
    "model: Union[PreTrainedModel, PeftModel, None]\n",
    "lora_config: Optional[LoraConfig]\n",
    "trainer: Optional[LMTrainer]\n",
    "```"
   ],
   "metadata": {
    "id": "FjOvBBY6Iylu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment = Experiment(config=config, train_dataset=train_dataset)"
   ],
   "metadata": {
    "id": "q051EACF6_6F"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🏗 Build the experiment\n",
    "\n",
    "At this point, we're setting up all the components needed for training."
   ],
   "metadata": {
    "id": "c_LNu8E4JPIW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment.build()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_n-_AZ56_2z",
    "outputId": "98b8f5ef-4c43-4c43-b716-1854ae65efe0"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:08:12.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment building has started\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig:\n",
      "{\n",
      "  \"experiment_key\": \"base\",\n",
      "  \"save_safetensors\": true,\n",
      "  \"max_shard_size\": \"10GB\",\n",
      "  \"local_rank\": 0,\n",
      "  \"use_gradient_checkpointing\": false,\n",
      "  \"trainer_key\": \"lm\",\n",
      "  \"force_fp32\": false,\n",
      "  \"force_fp16\": false,\n",
      "  \"from_gptq\": false,\n",
      "  \"huggingface_hub_token\": null,\n",
      "  \"deepspeed_stage\": 0,\n",
      "  \"deepspeed_config_path\": null,\n",
      "  \"fsdp_strategy\": \"\",\n",
      "  \"fsdp_offload\": true,\n",
      "  \"seed\": 42,\n",
      "  \"stabilize\": false,\n",
      "  \"path_to_env_file\": \"./.env\",\n",
      "  \"prepare_dataset\": true,\n",
      "  \"lora_hub_model_id\": null,\n",
      "  \"lora_model_local_path\": null,\n",
      "  \"fused_model_local_path\": null,\n",
      "  \"fuse_after_training\": false,\n",
      "  \"quantization_dataset_id\": null,\n",
      "  \"quantization_max_samples\": 1024,\n",
      "  \"quantized_model_path\": \"./quantized_model/\",\n",
      "  \"quantized_hub_model_id\": null,\n",
      "  \"quantized_hub_private_repo\": true,\n",
      "  \"dataset_key\": \"soda\",\n",
      "  \"train_local_path_to_data\": \"./train.jsonl\",\n",
      "  \"eval_local_path_to_data\": null,\n",
      "  \"shuffle\": true,\n",
      "  \"max_eval_samples\": 1000,\n",
      "  \"add_eval_to_train_if_no_path\": false,\n",
      "  \"tokenizer_name_or_path\": null,\n",
      "  \"tokenizer_use_fast\": null,\n",
      "  \"tokenizer_padding_side\": null,\n",
      "  \"collator_key\": \"lm\",\n",
      "  \"max_length\": 2048,\n",
      "  \"model_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"push_to_hub_bos_add_bos_token\": false,\n",
      "  \"use_flash_attention_2\": false,\n",
      "  \"trust_remote_code\": false,\n",
      "  \"device_map\": null,\n",
      "  \"prepare_model_for_kbit_training\": null,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"load_in_4bit\": false,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_quantize_after_model_init\": false,\n",
      "  \"gptq_bits\": 4,\n",
      "  \"gptq_group_size\": 128,\n",
      "  \"gptq_disable_exllama\": true,\n",
      "  \"apply_lora\": true,\n",
      "  \"lora_rank\": 8,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"raw_lora_target_modules\": \"all\",\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"do_eval\": false,\n",
      "  \"per_device_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": null,\n",
      "  \"eval_delay\": 0,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"max_steps\": null,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"logging_steps\": 10,\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"push_to_hub\": false,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_private_repo\": true,\n",
      "  \"report_to_wandb\": false,\n",
      "  \"wandb_api_key\": null,\n",
      "  \"wandb_project\": null,\n",
      "  \"wandb_entity\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig saved\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecks passed successfully\u001b[0m\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "\u001b[32m2023-11-15 11:08:12.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining arguments was built:\n",
      "{\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"overwrite_output_dir\": false,\n",
      "  \"do_train\": false,\n",
      "  \"do_eval\": false,\n",
      "  \"do_predict\": false,\n",
      "  \"evaluation_strategy\": \"no\",\n",
      "  \"prediction_loss_only\": false,\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"per_device_eval_batch_size\": 2,\n",
      "  \"per_gpu_train_batch_size\": null,\n",
      "  \"per_gpu_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": 1,\n",
      "  \"eval_delay\": 0,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"adam_beta1\": 0.9,\n",
      "  \"adam_beta2\": 0.999,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"max_steps\": -1,\n",
      "  \"lr_scheduler_type\": \"linear\",\n",
      "  \"warmup_ratio\": 0.0,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"log_level\": \"info\",\n",
      "  \"log_level_replica\": \"warning\",\n",
      "  \"log_on_each_node\": true,\n",
      "  \"logging_dir\": \"./outputs/runs/Nov15_11-08-12_f0fdbaff8b8c\",\n",
      "  \"logging_strategy\": \"steps\",\n",
      "  \"logging_first_step\": true,\n",
      "  \"logging_steps\": 10,\n",
      "  \"logging_nan_inf_filter\": true,\n",
      "  \"save_strategy\": \"steps\",\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_on_each_node\": false,\n",
      "  \"no_cuda\": false,\n",
      "  \"use_cpu\": false,\n",
      "  \"use_mps_device\": false,\n",
      "  \"seed\": 42,\n",
      "  \"data_seed\": 42,\n",
      "  \"jit_mode_eval\": false,\n",
      "  \"use_ipex\": false,\n",
      "  \"bf16\": false,\n",
      "  \"fp16\": true,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"half_precision_backend\": \"auto\",\n",
      "  \"bf16_full_eval\": false,\n",
      "  \"fp16_full_eval\": false,\n",
      "  \"tf32\": null,\n",
      "  \"local_rank\": 0,\n",
      "  \"ddp_backend\": null,\n",
      "  \"tpu_num_cores\": null,\n",
      "  \"tpu_metrics_debug\": false,\n",
      "  \"debug\": [],\n",
      "  \"dataloader_drop_last\": false,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"dataloader_num_workers\": 0,\n",
      "  \"past_index\": -1,\n",
      "  \"run_name\": \"./outputs/\",\n",
      "  \"disable_tqdm\": false,\n",
      "  \"remove_unused_columns\": false,\n",
      "  \"label_names\": null,\n",
      "  \"load_best_model_at_end\": false,\n",
      "  \"metric_for_best_model\": \"loss\",\n",
      "  \"greater_is_better\": false,\n",
      "  \"ignore_data_skip\": false,\n",
      "  \"fsdp\": [],\n",
      "  \"fsdp_min_num_params\": 0,\n",
      "  \"fsdp_config\": {\n",
      "    \"min_num_params\": 0,\n",
      "    \"xla\": false,\n",
      "    \"xla_fsdp_grad_ckpt\": false\n",
      "  },\n",
      "  \"fsdp_transformer_layer_cls_to_wrap\": null,\n",
      "  \"deepspeed\": null,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"optim_args\": null,\n",
      "  \"adafactor\": false,\n",
      "  \"group_by_length\": false,\n",
      "  \"length_column_name\": \"length\",\n",
      "  \"report_to\": [\n",
      "    \"tensorboard\"\n",
      "  ],\n",
      "  \"ddp_find_unused_parameters\": null,\n",
      "  \"ddp_bucket_cap_mb\": null,\n",
      "  \"ddp_broadcast_buffers\": null,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"skip_memory_metrics\": true,\n",
      "  \"use_legacy_prediction_loop\": false,\n",
      "  \"push_to_hub\": false,\n",
      "  \"resume_from_checkpoint\": null,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_strategy\": \"checkpoint\",\n",
      "  \"hub_token\": \"<HUB_TOKEN>\",\n",
      "  \"hub_private_repo\": true,\n",
      "  \"hub_always_push\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"gradient_checkpointing_kwargs\": null,\n",
      "  \"include_inputs_for_metrics\": false,\n",
      "  \"fp16_backend\": \"auto\",\n",
      "  \"push_to_hub_model_id\": null,\n",
      "  \"push_to_hub_organization\": null,\n",
      "  \"push_to_hub_token\": \"<PUSH_TO_HUB_TOKEN>\",\n",
      "  \"mp_parameters\": \"\",\n",
      "  \"auto_find_batch_size\": false,\n",
      "  \"full_determinism\": false,\n",
      "  \"torchdynamo\": null,\n",
      "  \"ray_scope\": \"last\",\n",
      "  \"ddp_timeout\": 1800,\n",
      "  \"torch_compile\": false,\n",
      "  \"torch_compile_backend\": null,\n",
      "  \"torch_compile_mode\": null,\n",
      "  \"dispatch_batches\": null,\n",
      "  \"split_batches\": false,\n",
      "  \"include_tokens_per_second\": false,\n",
      "  \"neftune_noise_alpha\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEval dataset is None\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:08:12.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTokenizer facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mCollator LMCollator was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:12.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuantization config is None. Model will be loaded using torch.float16\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/pytorch_model.bin\n",
      "Instantiating OPTForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-350m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:08:28.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:28.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mLoRA applied to the model facebook/opt-350m\u001b[0m\n",
      "Using auto half precision backend\n",
      "\u001b[32m2023-11-15 11:08:28.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTrainer LMTrainer was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:08:28.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment built successfully\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🚄 Run experiment"
   ],
   "metadata": {
    "id": "1WFN6ISmJnFm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment.run()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "rzPdKTYW6_yF",
    "outputId": "ab18c928-d591-46e2-eea3-a2ebe4aabf43"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:08:28.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining will start soon\u001b[0m\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 3,563,520\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.748600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.797700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.994300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.937400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.473700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving model checkpoint to ./outputs/checkpoint-100\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:02.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining end\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:02.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel saved to ./outputs/\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🎉 Done!\n",
    "\n",
    "You are trained a model using `xllm`"
   ],
   "metadata": {
    "id": "gU3Dy3FlKoCg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fuse model"
   ],
   "metadata": {
    "id": "UPo9UQuptnuu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# experiment.fuse_lora()"
   ],
   "metadata": {
    "id": "r__1558mtngt"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the model"
   ],
   "metadata": {
    "id": "BvihxRPHKuGd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# experiment.model"
   ],
   "metadata": {
    "id": "63ibIRNQLiTS"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## You can save the model\n",
    "\n",
    "If you have not fuse the model, then only the LoRA weights will be saved."
   ],
   "metadata": {
    "id": "sfzXFLW2Lnpd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# experiment.model.save_pretrained(\"./trained_model/\")"
   ],
   "metadata": {
    "id": "wj6oheYCLkv5"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## You could push the model to the HuggingFace Hub\n",
    "\n",
    "If you have not fuse the model, then only the LoRA weights will be saved.\n",
    "\n",
    "Make sure you are logged in HuggingFace Hub. You can run this command:\n",
    "\n",
    "```python\n",
    "!huggingface-cli login\n",
    "```\n",
    "\n",
    "Or you can set the environment variable with your Access token. You can find your token here: https://huggingface.co/settings/tokens\n",
    "\n",
    "```\n",
    "import os\n",
    "\n",
    "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = \"YOUR_ACCESS_TOKEN\"\n",
    "```"
   ],
   "metadata": {
    "id": "jgkDeErVLq-H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# push the model and the tokenizer to the HuggingFace Hub\n",
    "# experiment.push_to_hub(\n",
    "#     repo_id=\"YOUR_LOGIN_AT_HF_HUB/MODEL_NAME\",\n",
    "#     private=False,\n",
    "#     safe_serialization=True\n",
    "# )"
   ],
   "metadata": {
    "id": "_jhP6AG_MIWJ"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 🎉 Done!\n",
    "\n",
    "You've trained the model using `xllm` and uploaded it to the hub"
   ],
   "metadata": {
    "id": "0nBPNvljMhQx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add QLoRA\n",
    "\n",
    "To train the `QLoRA` model, we need to load the backbone model using `bitsandbytes` library and int4 (or int8) weights."
   ],
   "metadata": {
    "id": "i0cnsI3Quizi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# config with QLoRA\n",
    "config = Config(\n",
    "    model_name_or_path=\"facebook/opt-350m\",\n",
    "    apply_lora=True,\n",
    "    load_in_4bit=True,\n",
    "    prepare_model_for_kbit_training=True,\n",
    ")"
   ],
   "metadata": {
    "id": "Jwj6AQjWvCPA"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### You can explicitly specify the values of additional parameters in bitsandbytes quantization"
   ],
   "metadata": {
    "id": "MKya31NSvMHu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # extended config with QLoRA\n",
    "# config = Config(\n",
    "#     model_name_or_path=\"facebook/opt-350m\",\n",
    "#     apply_lora=True,\n",
    "#     load_in_4bit=True,\n",
    "#     prepare_model_for_kbit_training=True,\n",
    "#     llm_int8_threshold=6.0,\n",
    "#     llm_int8_has_fp16_weight=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "# )"
   ],
   "metadata": {
    "id": "5Qq9t9VfvPg9"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All other steps are the same"
   ],
   "metadata": {
    "id": "jY7omBtEv2V6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = [\"Hello!\", \"How are you?\", \"Are you okay?\"] * 100\n",
    "train_dataset = GeneralDataset.from_list(data=train_data)\n",
    "experiment = Experiment(config=config, train_dataset=train_dataset)\n",
    "experiment.build()\n",
    "experiment.run()\n",
    "# experiment.fuse_lora()"
   ],
   "metadata": {
    "id": "FWhYuHl8v1xr",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "8c219370-47bf-46b6-8562-50ea933369d2"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:09:02.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment building has started\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:02.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig:\n",
      "{\n",
      "  \"experiment_key\": \"base\",\n",
      "  \"save_safetensors\": true,\n",
      "  \"max_shard_size\": \"10GB\",\n",
      "  \"local_rank\": 0,\n",
      "  \"use_gradient_checkpointing\": false,\n",
      "  \"trainer_key\": \"lm\",\n",
      "  \"force_fp32\": false,\n",
      "  \"force_fp16\": false,\n",
      "  \"from_gptq\": false,\n",
      "  \"huggingface_hub_token\": null,\n",
      "  \"deepspeed_stage\": 0,\n",
      "  \"deepspeed_config_path\": null,\n",
      "  \"fsdp_strategy\": \"\",\n",
      "  \"fsdp_offload\": true,\n",
      "  \"seed\": 42,\n",
      "  \"stabilize\": false,\n",
      "  \"path_to_env_file\": \"./.env\",\n",
      "  \"prepare_dataset\": true,\n",
      "  \"lora_hub_model_id\": null,\n",
      "  \"lora_model_local_path\": null,\n",
      "  \"fused_model_local_path\": null,\n",
      "  \"fuse_after_training\": false,\n",
      "  \"quantization_dataset_id\": null,\n",
      "  \"quantization_max_samples\": 1024,\n",
      "  \"quantized_model_path\": \"./quantized_model/\",\n",
      "  \"quantized_hub_model_id\": null,\n",
      "  \"quantized_hub_private_repo\": true,\n",
      "  \"dataset_key\": \"soda\",\n",
      "  \"train_local_path_to_data\": \"./train.jsonl\",\n",
      "  \"eval_local_path_to_data\": null,\n",
      "  \"shuffle\": true,\n",
      "  \"max_eval_samples\": 1000,\n",
      "  \"add_eval_to_train_if_no_path\": false,\n",
      "  \"tokenizer_name_or_path\": null,\n",
      "  \"tokenizer_use_fast\": null,\n",
      "  \"tokenizer_padding_side\": null,\n",
      "  \"collator_key\": \"lm\",\n",
      "  \"max_length\": 2048,\n",
      "  \"model_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"push_to_hub_bos_add_bos_token\": false,\n",
      "  \"use_flash_attention_2\": false,\n",
      "  \"trust_remote_code\": false,\n",
      "  \"device_map\": null,\n",
      "  \"prepare_model_for_kbit_training\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_quantize_after_model_init\": false,\n",
      "  \"gptq_bits\": 4,\n",
      "  \"gptq_group_size\": 128,\n",
      "  \"gptq_disable_exllama\": true,\n",
      "  \"apply_lora\": true,\n",
      "  \"lora_rank\": 8,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"raw_lora_target_modules\": \"all\",\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"do_eval\": false,\n",
      "  \"per_device_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": null,\n",
      "  \"eval_delay\": 0,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"max_steps\": null,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"logging_steps\": 10,\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"push_to_hub\": false,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_private_repo\": true,\n",
      "  \"report_to_wandb\": false,\n",
      "  \"wandb_api_key\": null,\n",
      "  \"wandb_project\": null,\n",
      "  \"wandb_entity\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:03.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig saved\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:03.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecks passed successfully\u001b[0m\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "\u001b[32m2023-11-15 11:09:03.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining arguments was built:\n",
      "{\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"overwrite_output_dir\": false,\n",
      "  \"do_train\": false,\n",
      "  \"do_eval\": false,\n",
      "  \"do_predict\": false,\n",
      "  \"evaluation_strategy\": \"no\",\n",
      "  \"prediction_loss_only\": false,\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"per_device_eval_batch_size\": 2,\n",
      "  \"per_gpu_train_batch_size\": null,\n",
      "  \"per_gpu_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": 1,\n",
      "  \"eval_delay\": 0,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"adam_beta1\": 0.9,\n",
      "  \"adam_beta2\": 0.999,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"max_steps\": -1,\n",
      "  \"lr_scheduler_type\": \"linear\",\n",
      "  \"warmup_ratio\": 0.0,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"log_level\": \"info\",\n",
      "  \"log_level_replica\": \"warning\",\n",
      "  \"log_on_each_node\": true,\n",
      "  \"logging_dir\": \"./outputs/runs/Nov15_11-09-03_f0fdbaff8b8c\",\n",
      "  \"logging_strategy\": \"steps\",\n",
      "  \"logging_first_step\": true,\n",
      "  \"logging_steps\": 10,\n",
      "  \"logging_nan_inf_filter\": true,\n",
      "  \"save_strategy\": \"steps\",\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_on_each_node\": false,\n",
      "  \"no_cuda\": false,\n",
      "  \"use_cpu\": false,\n",
      "  \"use_mps_device\": false,\n",
      "  \"seed\": 42,\n",
      "  \"data_seed\": 42,\n",
      "  \"jit_mode_eval\": false,\n",
      "  \"use_ipex\": false,\n",
      "  \"bf16\": false,\n",
      "  \"fp16\": true,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"half_precision_backend\": \"auto\",\n",
      "  \"bf16_full_eval\": false,\n",
      "  \"fp16_full_eval\": false,\n",
      "  \"tf32\": null,\n",
      "  \"local_rank\": 0,\n",
      "  \"ddp_backend\": null,\n",
      "  \"tpu_num_cores\": null,\n",
      "  \"tpu_metrics_debug\": false,\n",
      "  \"debug\": [],\n",
      "  \"dataloader_drop_last\": false,\n",
      "  \"eval_steps\": 1000,\n",
      "  \"dataloader_num_workers\": 0,\n",
      "  \"past_index\": -1,\n",
      "  \"run_name\": \"./outputs/\",\n",
      "  \"disable_tqdm\": false,\n",
      "  \"remove_unused_columns\": false,\n",
      "  \"label_names\": null,\n",
      "  \"load_best_model_at_end\": false,\n",
      "  \"metric_for_best_model\": \"loss\",\n",
      "  \"greater_is_better\": false,\n",
      "  \"ignore_data_skip\": false,\n",
      "  \"fsdp\": [],\n",
      "  \"fsdp_min_num_params\": 0,\n",
      "  \"fsdp_config\": {\n",
      "    \"min_num_params\": 0,\n",
      "    \"xla\": false,\n",
      "    \"xla_fsdp_grad_ckpt\": false\n",
      "  },\n",
      "  \"fsdp_transformer_layer_cls_to_wrap\": null,\n",
      "  \"deepspeed\": null,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"optim_args\": null,\n",
      "  \"adafactor\": false,\n",
      "  \"group_by_length\": false,\n",
      "  \"length_column_name\": \"length\",\n",
      "  \"report_to\": [\n",
      "    \"tensorboard\"\n",
      "  ],\n",
      "  \"ddp_find_unused_parameters\": null,\n",
      "  \"ddp_bucket_cap_mb\": null,\n",
      "  \"ddp_broadcast_buffers\": null,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"skip_memory_metrics\": true,\n",
      "  \"use_legacy_prediction_loop\": false,\n",
      "  \"push_to_hub\": false,\n",
      "  \"resume_from_checkpoint\": null,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_strategy\": \"checkpoint\",\n",
      "  \"hub_token\": \"<HUB_TOKEN>\",\n",
      "  \"hub_private_repo\": true,\n",
      "  \"hub_always_push\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"gradient_checkpointing_kwargs\": null,\n",
      "  \"include_inputs_for_metrics\": false,\n",
      "  \"fp16_backend\": \"auto\",\n",
      "  \"push_to_hub_model_id\": null,\n",
      "  \"push_to_hub_organization\": null,\n",
      "  \"push_to_hub_token\": \"<PUSH_TO_HUB_TOKEN>\",\n",
      "  \"mp_parameters\": \"\",\n",
      "  \"auto_find_batch_size\": false,\n",
      "  \"full_determinism\": false,\n",
      "  \"torchdynamo\": null,\n",
      "  \"ray_scope\": \"last\",\n",
      "  \"ddp_timeout\": 1800,\n",
      "  \"torch_compile\": false,\n",
      "  \"torch_compile_backend\": null,\n",
      "  \"torch_compile_mode\": null,\n",
      "  \"dispatch_batches\": null,\n",
      "  \"split_batches\": false,\n",
      "  \"include_tokens_per_second\": false,\n",
      "  \"neftune_noise_alpha\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:03.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mEval dataset is None\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:03.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTokenizer facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:03.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mCollator LMCollator was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:03.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuantization config was built:\n",
      "{\n",
      "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"load_in_4bit\": true\n",
      "}\n",
      "\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' \n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/pytorch_model.bin\n",
      "Instantiating OPTForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Detected 4-bit loading: activating 4-bit loading for this model\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-350m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:04.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel prepared for kbit training. Gradient checkpointing: False\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:04.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:04.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mLoRA applied to the model facebook/opt-350m\u001b[0m\n",
      "Using auto half precision backend\n",
      "\u001b[32m2023-11-15 11:09:04.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTrainer LMTrainer was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:04.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment built successfully\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:04.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining will start soon\u001b[0m\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 3,563,520\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.945300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.629700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.713300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.829100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.735500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.428500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Saving model checkpoint to ./outputs/checkpoint-100\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:53.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining end\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel saved to ./outputs/\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## You also can add `Gradient Checkpointing`\n",
    "\n",
    "This will help to use `less GPU memory` during training, that is, you will be able to learn more than without this technique. The disadvantages of this technique is slowing down the forward step, that is, `slowing down training`.\n",
    "\n",
    "Summarizing: you will be training larger models (for example 7B in colab), but at the expense of training speed."
   ],
   "metadata": {
    "id": "rYpCTXD1z48a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# config = Config(\n",
    "#     model_name_or_path=\"facebook/opt-350m\",\n",
    "\n",
    "#     use_gradient_checkpointing=True,\n",
    "\n",
    "#     apply_lora=True,\n",
    "#     load_in_4bit=True,\n",
    "#     prepare_model_for_kbit_training=True,\n",
    "# )"
   ],
   "metadata": {
    "id": "4-_uG-aN0s8F"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add eval data"
   ],
   "metadata": {
    "id": "UOG_A3itJzvR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup config\n",
    "\n",
    "- `do_eval` for turn on evaluation  \n",
    "- `eval_steps` how often we should run evaluation"
   ],
   "metadata": {
    "id": "Kw7FFI0TJ6hc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = Config(\n",
    "    model_name_or_path=\"facebook/opt-350m\",\n",
    "    apply_lora=True,\n",
    "    load_in_4bit=True,\n",
    "    prepare_model_for_kbit_training=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=50,\n",
    ")"
   ],
   "metadata": {
    "id": "ue9wpOUy6--4"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make dummy eval dataset"
   ],
   "metadata": {
    "id": "xMIA8MwoKM8V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "eval_data = [\"Hi\", \"Sup?\"] * 10"
   ],
   "metadata": {
    "id": "BLEMaWo2HJVs"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make a `xllm` eval dataset"
   ],
   "metadata": {
    "id": "EF2U5TZMKUDW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "eval_dataset = GeneralDataset.from_list(eval_data)"
   ],
   "metadata": {
    "id": "exF7XB2AKRcn"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init experiment with the `eval_dataset`"
   ],
   "metadata": {
    "id": "oyHOGsJuQg0D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment = Experiment(config=config, train_dataset=train_dataset, eval_dataset=eval_dataset)"
   ],
   "metadata": {
    "id": "ps856ZWwKdYg"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build experiment"
   ],
   "metadata": {
    "id": "DC81sYGfQkDy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment.build()"
   ],
   "metadata": {
    "id": "k5LKSvT3KaYS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "26686f2d-2d7c-428e-94df-7abfe76bf0a2"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:09:53.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment building has started\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig:\n",
      "{\n",
      "  \"experiment_key\": \"base\",\n",
      "  \"save_safetensors\": true,\n",
      "  \"max_shard_size\": \"10GB\",\n",
      "  \"local_rank\": 0,\n",
      "  \"use_gradient_checkpointing\": false,\n",
      "  \"trainer_key\": \"lm\",\n",
      "  \"force_fp32\": false,\n",
      "  \"force_fp16\": false,\n",
      "  \"from_gptq\": false,\n",
      "  \"huggingface_hub_token\": null,\n",
      "  \"deepspeed_stage\": 0,\n",
      "  \"deepspeed_config_path\": null,\n",
      "  \"fsdp_strategy\": \"\",\n",
      "  \"fsdp_offload\": true,\n",
      "  \"seed\": 42,\n",
      "  \"stabilize\": false,\n",
      "  \"path_to_env_file\": \"./.env\",\n",
      "  \"prepare_dataset\": true,\n",
      "  \"lora_hub_model_id\": null,\n",
      "  \"lora_model_local_path\": null,\n",
      "  \"fused_model_local_path\": null,\n",
      "  \"fuse_after_training\": false,\n",
      "  \"quantization_dataset_id\": null,\n",
      "  \"quantization_max_samples\": 1024,\n",
      "  \"quantized_model_path\": \"./quantized_model/\",\n",
      "  \"quantized_hub_model_id\": null,\n",
      "  \"quantized_hub_private_repo\": true,\n",
      "  \"dataset_key\": \"soda\",\n",
      "  \"train_local_path_to_data\": \"./train.jsonl\",\n",
      "  \"eval_local_path_to_data\": null,\n",
      "  \"shuffle\": true,\n",
      "  \"max_eval_samples\": 1000,\n",
      "  \"add_eval_to_train_if_no_path\": false,\n",
      "  \"tokenizer_name_or_path\": null,\n",
      "  \"tokenizer_use_fast\": null,\n",
      "  \"tokenizer_padding_side\": null,\n",
      "  \"collator_key\": \"lm\",\n",
      "  \"max_length\": 2048,\n",
      "  \"model_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"push_to_hub_bos_add_bos_token\": false,\n",
      "  \"use_flash_attention_2\": false,\n",
      "  \"trust_remote_code\": false,\n",
      "  \"device_map\": null,\n",
      "  \"prepare_model_for_kbit_training\": true,\n",
      "  \"load_in_8bit\": false,\n",
      "  \"load_in_4bit\": true,\n",
      "  \"llm_int8_threshold\": 6.0,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_quantize_after_model_init\": false,\n",
      "  \"gptq_bits\": 4,\n",
      "  \"gptq_group_size\": 128,\n",
      "  \"gptq_disable_exllama\": true,\n",
      "  \"apply_lora\": true,\n",
      "  \"lora_rank\": 8,\n",
      "  \"lora_alpha\": 32,\n",
      "  \"lora_dropout\": 0.1,\n",
      "  \"raw_lora_target_modules\": \"all\",\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"do_eval\": true,\n",
      "  \"per_device_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": null,\n",
      "  \"eval_delay\": 0,\n",
      "  \"eval_steps\": 50,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"max_steps\": null,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"logging_steps\": 10,\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"push_to_hub\": false,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_private_repo\": true,\n",
      "  \"report_to_wandb\": false,\n",
      "  \"wandb_api_key\": null,\n",
      "  \"wandb_project\": null,\n",
      "  \"wandb_entity\": null\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mConfig saved\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mChecks passed successfully\u001b[0m\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "\u001b[32m2023-11-15 11:09:53.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining arguments was built:\n",
      "{\n",
      "  \"output_dir\": \"./outputs/\",\n",
      "  \"overwrite_output_dir\": false,\n",
      "  \"do_train\": false,\n",
      "  \"do_eval\": true,\n",
      "  \"do_predict\": false,\n",
      "  \"evaluation_strategy\": \"steps\",\n",
      "  \"prediction_loss_only\": false,\n",
      "  \"per_device_train_batch_size\": 2,\n",
      "  \"per_device_eval_batch_size\": 2,\n",
      "  \"per_gpu_train_batch_size\": null,\n",
      "  \"per_gpu_eval_batch_size\": null,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"eval_accumulation_steps\": 1,\n",
      "  \"eval_delay\": 0,\n",
      "  \"learning_rate\": 0.0002,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"adam_beta1\": 0.9,\n",
      "  \"adam_beta2\": 0.999,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"num_train_epochs\": 1,\n",
      "  \"max_steps\": -1,\n",
      "  \"lr_scheduler_type\": \"linear\",\n",
      "  \"warmup_ratio\": 0.0,\n",
      "  \"warmup_steps\": 1000,\n",
      "  \"log_level\": \"info\",\n",
      "  \"log_level_replica\": \"warning\",\n",
      "  \"log_on_each_node\": true,\n",
      "  \"logging_dir\": \"./outputs/runs/Nov15_11-09-53_f0fdbaff8b8c\",\n",
      "  \"logging_strategy\": \"steps\",\n",
      "  \"logging_first_step\": true,\n",
      "  \"logging_steps\": 10,\n",
      "  \"logging_nan_inf_filter\": true,\n",
      "  \"save_strategy\": \"steps\",\n",
      "  \"save_steps\": 100,\n",
      "  \"save_total_limit\": 1,\n",
      "  \"save_safetensors\": true,\n",
      "  \"save_on_each_node\": false,\n",
      "  \"no_cuda\": false,\n",
      "  \"use_cpu\": false,\n",
      "  \"use_mps_device\": false,\n",
      "  \"seed\": 42,\n",
      "  \"data_seed\": 42,\n",
      "  \"jit_mode_eval\": false,\n",
      "  \"use_ipex\": false,\n",
      "  \"bf16\": false,\n",
      "  \"fp16\": true,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"half_precision_backend\": \"auto\",\n",
      "  \"bf16_full_eval\": false,\n",
      "  \"fp16_full_eval\": false,\n",
      "  \"tf32\": null,\n",
      "  \"local_rank\": 0,\n",
      "  \"ddp_backend\": null,\n",
      "  \"tpu_num_cores\": null,\n",
      "  \"tpu_metrics_debug\": false,\n",
      "  \"debug\": [],\n",
      "  \"dataloader_drop_last\": false,\n",
      "  \"eval_steps\": 50,\n",
      "  \"dataloader_num_workers\": 0,\n",
      "  \"past_index\": -1,\n",
      "  \"run_name\": \"./outputs/\",\n",
      "  \"disable_tqdm\": false,\n",
      "  \"remove_unused_columns\": false,\n",
      "  \"label_names\": null,\n",
      "  \"load_best_model_at_end\": false,\n",
      "  \"metric_for_best_model\": \"eval_loss\",\n",
      "  \"greater_is_better\": false,\n",
      "  \"ignore_data_skip\": false,\n",
      "  \"fsdp\": [],\n",
      "  \"fsdp_min_num_params\": 0,\n",
      "  \"fsdp_config\": {\n",
      "    \"min_num_params\": 0,\n",
      "    \"xla\": false,\n",
      "    \"xla_fsdp_grad_ckpt\": false\n",
      "  },\n",
      "  \"fsdp_transformer_layer_cls_to_wrap\": null,\n",
      "  \"deepspeed\": null,\n",
      "  \"label_smoothing_factor\": 0.0,\n",
      "  \"optim\": \"paged_adamw_8bit\",\n",
      "  \"optim_args\": null,\n",
      "  \"adafactor\": false,\n",
      "  \"group_by_length\": false,\n",
      "  \"length_column_name\": \"length\",\n",
      "  \"report_to\": [\n",
      "    \"tensorboard\"\n",
      "  ],\n",
      "  \"ddp_find_unused_parameters\": null,\n",
      "  \"ddp_bucket_cap_mb\": null,\n",
      "  \"ddp_broadcast_buffers\": null,\n",
      "  \"dataloader_pin_memory\": true,\n",
      "  \"skip_memory_metrics\": true,\n",
      "  \"use_legacy_prediction_loop\": false,\n",
      "  \"push_to_hub\": false,\n",
      "  \"resume_from_checkpoint\": null,\n",
      "  \"hub_model_id\": null,\n",
      "  \"hub_strategy\": \"checkpoint\",\n",
      "  \"hub_token\": \"<HUB_TOKEN>\",\n",
      "  \"hub_private_repo\": true,\n",
      "  \"hub_always_push\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"gradient_checkpointing_kwargs\": null,\n",
      "  \"include_inputs_for_metrics\": false,\n",
      "  \"fp16_backend\": \"auto\",\n",
      "  \"push_to_hub_model_id\": null,\n",
      "  \"push_to_hub_organization\": null,\n",
      "  \"push_to_hub_token\": \"<PUSH_TO_HUB_TOKEN>\",\n",
      "  \"mp_parameters\": \"\",\n",
      "  \"auto_find_batch_size\": false,\n",
      "  \"full_determinism\": false,\n",
      "  \"torchdynamo\": null,\n",
      "  \"ray_scope\": \"last\",\n",
      "  \"ddp_timeout\": 1800,\n",
      "  \"torch_compile\": false,\n",
      "  \"torch_compile_backend\": null,\n",
      "  \"torch_compile_mode\": null,\n",
      "  \"dispatch_batches\": null,\n",
      "  \"split_batches\": false,\n",
      "  \"include_tokens_per_second\": false,\n",
      "  \"neftune_noise_alpha\": null\n",
      "}\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:53.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTokenizer facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mCollator LMCollator was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:53.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mQuantization config was built:\n",
      "{\n",
      "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"llm_int8_has_fp16_weight\": true,\n",
      "  \"load_in_4bit\": true\n",
      "}\n",
      "\u001b[0m\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/config.json\n",
      "Model config OPTConfig {\n",
      "  \"_name_or_path\": \"facebook/opt-350m\",\n",
      "  \"_remove_final_layer_norm\": false,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"OPTForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"do_layer_norm_before\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"enable_bias\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"init_std\": 0.02,\n",
      "  \"layer_norm_elementwise_affine\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"opt\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \"</s>\",\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.35.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50272,\n",
      "  \"word_embed_proj_dim\": 512\n",
      "}\n",
      "\n",
      "The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' \n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/pytorch_model.bin\n",
      "Instantiating OPTForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Detected 4-bit loading: activating 4-bit loading for this model\n",
      "All model checkpoint weights were used when initializing OPTForCausalLM.\n",
      "\n",
      "All the weights of OPTForCausalLM were initialized from the model checkpoint at facebook/opt-350m.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use OPTForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--opt-350m/snapshots/08ab08cc4b72ff5593870b5d527cf4230323703c/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "\u001b[32m2023-11-15 11:09:54.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel prepared for kbit training. Gradient checkpointing: False\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:54.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel facebook/opt-350m was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:55.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mLoRA applied to the model facebook/opt-350m\u001b[0m\n",
      "Using auto half precision backend\n",
      "\u001b[32m2023-11-15 11:09:55.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTrainer LMTrainer was built\u001b[0m\n",
      "\u001b[32m2023-11-15 11:09:55.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mExperiment built successfully\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run experiment"
   ],
   "metadata": {
    "id": "jRCjV7UEQlhp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment.run()"
   ],
   "metadata": {
    "id": "NadhNd39KRRq",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "outputId": "089f6e75-2221-4f55-a25e-64b815bd0a30"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2023-11-15 11:09:55.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining will start soon\u001b[0m\n",
      "***** Running training *****\n",
      "  Num examples = 300\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 3,563,520\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.216700</td>\n",
       "      <td>7.310188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.829100</td>\n",
       "      <td>8.282642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.428500</td>\n",
       "      <td>8.972834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./outputs/checkpoint-100\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20\n",
      "  Batch size = 2\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m2023-11-15 11:10:47.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mTraining end\u001b[0m\n",
      "\u001b[32m2023-11-15 11:10:47.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mxllm.utils.logger\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mModel saved to ./outputs/\u001b[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 🎉 You are awesome!\n",
    "\n",
    "## Now you know how to prototype models using `xllm`\n",
    "\n",
    "### Explore more examples at X—LLM repo\n",
    "\n",
    "https://github.com/BobaZooba/xllm\n",
    "\n",
    "Useful materials:\n",
    "\n",
    "- [X—LLM Repo](https://github.com/BobaZooba/xllm): main repo of the `xllm` library\n",
    "- [Quickstart](https://github.com/KompleteAI/xllm/tree/docs-v1#quickstart-): basics of `xllm`\n",
    "- [Examples](https://github.com/BobaZooba/xllm/examples): minimal examples of using `xllm`\n",
    "- [Guide](https://github.com/BobaZooba/xllm/blob/main/GUIDE.md): here, we go into detail about everything the library can\n",
    "  do\n",
    "- [Demo project](https://github.com/BobaZooba/xllm-demo): here's a minimal step-by-step example of how to use X—LLM and fit it\n",
    "  into your own project\n",
    "- [WeatherGPT](https://github.com/BobaZooba/wgpt): this repository features an example of how to utilize the xllm library. Included is a solution for a common type of assessment given to LLM engineers, who typically earn between $120,000 to $140,000 annually\n",
    "- [Shurale](https://github.com/BobaZooba/shurale): project with the finetuned 7B Mistal model\n"
   ],
   "metadata": {
    "id": "NlX7tO65hOQU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tale Quest\n",
    "\n",
    "`Tale Quest` is my personal project which was built using `xllm` and `Shurale`. It's an interactive text-based game\n",
    "in `Telegram` with dynamic AI characters, offering infinite scenarios\n",
    "\n",
    "You will get into exciting journeys and complete fascinating quests. Chat\n",
    "with `George Orwell`, `Tech Entrepreneur`, `Young Wizard`, `Noir Detective`, `Femme Fatale` and many more\n",
    "\n",
    "Try it now: [https://t.me/talequestbot](https://t.me/TaleQuestBot?start=Z2g)"
   ],
   "metadata": {
    "id": "5wJJrKnglAkK"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fFfDfFiCpDPv"
   },
   "execution_count": 25,
   "outputs": []
  }
 ]
}
